{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcVasiy7EpM9",
        "outputId": "5204f97b-c294-4f86-cc5a-40d666186133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m371.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m959.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio transformers torch pillow python-dotenv huggingface_hub docling-core opencv-python-headless torch_xla"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "txgELFBHQhVH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "from PIL import Image\n",
        "from docling_core.types.doc import DoclingDocument\n",
        "from docling_core.types.doc.document import DocTagsDocument\n",
        "import gradio as gr\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Model Initialization\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = AutoProcessor.from_pretrained(\"ds4sd/SmolDocling-256M-preview\")\n",
        "model = AutoModelForVision2Seq.from_pretrained(\"ds4sd/SmolDocling-256M-preview\").to(device)\n",
        "\n",
        "# Processing function\n",
        "def process_image(image, task_type):\n",
        "    start_time = time.time()\n",
        "\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": task_type}]\n",
        "    }]\n",
        "\n",
        "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=1024)\n",
        "    prompt_length = inputs.input_ids.shape[1]\n",
        "    trimmed_generated_ids = generated_ids[:, prompt_length:]\n",
        "\n",
        "    doctags = processor.batch_decode(trimmed_generated_ids, skip_special_tokens=False)[0].lstrip()\n",
        "    doctags = doctags.replace(\"<end_of_utterance>\", \"\").strip()\n",
        "\n",
        "    if task_type.strip().lower() == \"convert formula to latex.\":\n",
        "        md_content = f\"$$\\n{doctags}\\n$$\"\n",
        "    else:\n",
        "        doctags_doc = DocTagsDocument.from_doctags_and_image_pairs([doctags], [image])\n",
        "        doc = DoclingDocument(name=\"Document\")\n",
        "        doc.load_from_doctags(doctags_doc)\n",
        "        md_content = doc.export_to_markdown()\n",
        "\n",
        "    processing_time = time.time() - start_time\n",
        "    return doctags, md_content, f\"{processing_time:.2f} seconds\"\n",
        "\n",
        "# Batch processing function\n",
        "def process_multiple_images(images, task_type):\n",
        "    results = []\n",
        "    for idx, image in enumerate(images, 1):\n",
        "        doctags, md_content, processing_time = process_image(image, task_type)\n",
        "        results.append({\n",
        "            \"Image #\": idx,\n",
        "            \"DocTags\": doctags,\n",
        "            \"Markdown\": md_content,\n",
        "            \"Processing Time\": processing_time\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Gradio Interface Function\n",
        "def gradio_fn(upload_type, single_image, multiple_images, task):\n",
        "    if upload_type == \"Single Image\" and single_image:\n",
        "        doctags, md_content, proc_time = process_image(single_image, task)\n",
        "        return doctags, md_content, proc_time, None\n",
        "    elif upload_type == \"Multiple Images\" and multiple_images:\n",
        "        all_results = process_multiple_images(multiple_images, task)\n",
        "        combined_doctags = \"\\n\\n---\\n\\n\".join([res[\"DocTags\"] for res in all_results])\n",
        "        combined_markdown = \"\\n\\n---\\n\\n\".join([res[\"Markdown\"] for res in all_results])\n",
        "        total_time = sum([float(res[\"Processing Time\"].split()[0]) for res in all_results])\n",
        "        df_results = pd.DataFrame(all_results)\n",
        "        return combined_doctags, combined_markdown, f\"{total_time:.2f} seconds\", df_results\n",
        "    else:\n",
        "        return \"\", \"\", \"No image uploaded.\", None\n",
        "\n",
        "# Task options with icons for better UX\n",
        "task_options = [\n",
        "    \"📄 Convert this page to docling.\",\n",
        "    \"📊 Convert this table to OTSL.\",\n",
        "    \"💻 Convert code to text.\",\n",
        "    \"🧮 Convert formula to latex.\",\n",
        "    \"📈 Convert chart to OTSL.\",\n",
        "    \"📑 Extract all section header elements on the page.\"\n",
        "]\n",
        "\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    # Header Section\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <div style='text-align: center;'>\n",
        "            <h1>🚀 SmolDocling OCR Application </h1>\n",
        "            <p>Extract text, tables, formulas, and more from images with ease.</p>\n",
        "            <img src='https://huggingface.co/front/assets/huggingface_logo.svg' width='150'>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Input Section\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 🖼️ Upload Image(s)\")\n",
        "            upload_type = gr.Radio(\n",
        "                [\"Single Image\", \"Multiple Images\"],\n",
        "                label=\"Choose Upload Type\",\n",
        "                value=\"Single Image\",\n",
        "                elem_id=\"upload_type_radio\",\n",
        "                info=\"Select whether to upload one or multiple images\"\n",
        "            )\n",
        "            single_image = gr.Image(\n",
        "                type=\"pil\",\n",
        "                label=\"Upload Single Image\",\n",
        "                visible=True,\n",
        "                elem_id=\"single_image_input\",\n",
        "                show_download_button=True\n",
        "            )\n",
        "            multiple_images = gr.File(\n",
        "                file_count=\"multiple\",\n",
        "                file_types=[\"image\"],\n",
        "                label=\"Upload Multiple Images\",\n",
        "                visible=False,\n",
        "                elem_id=\"multiple_images_input\"\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### ⚙️ Task Selection\")\n",
        "            task = gr.Dropdown(\n",
        "                choices=task_options,\n",
        "                label=\"Select OCR Task\",\n",
        "                value=task_options[0],\n",
        "                elem_id=\"task_dropdown\",\n",
        "                info=\"Choose the type of OCR task to perform\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\n",
        "                \"🚀 Process Images\",\n",
        "                variant=\"primary\",\n",
        "                elem_id=\"submit_btn\"\n",
        "            )\n",
        "\n",
        "    # Output Section\n",
        "    gr.Markdown(\"### 📤 Results\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"🔍 DocTags\"):\n",
        "            doctags_output = gr.Textbox(\n",
        "                label=\"Extracted DocTags\",\n",
        "                placeholder=\"DocTags will appear here after processing...\",\n",
        "                lines=10,\n",
        "                elem_id=\"doctags_output\",\n",
        "                show_copy_button=True\n",
        "            )\n",
        "        with gr.TabItem(\"📜 Markdown\"):\n",
        "            markdown_output = gr.Markdown(\n",
        "                label=\"Markdown Output\",\n",
        "                value=\"Markdown output will appear here after processing...\"\n",
        "            )\n",
        "        with gr.TabItem(\"⏱️ Processing Time\"):\n",
        "            proc_time_output = gr.Textbox(\n",
        "                label=\"Total Processing Time\",\n",
        "                placeholder=\"Processing time will appear here after processing...\",\n",
        "                elem_id=\"proc_time_output\"\n",
        "            )\n",
        "        with gr.TabItem(\"📋 Detailed Results (Batch)\"):\n",
        "            df_output = gr.Dataframe(\n",
        "                label=\"Detailed Results for Multiple Images\",\n",
        "                elem_id=\"df_output\"\n",
        "            )\n",
        "\n",
        "    # Dynamic visibility logic for Single vs Multiple Image Upload\n",
        "    def update_visibility(upload_type):\n",
        "        return {\n",
        "            single_image: gr.update(visible=upload_type == \"Single Image\"),\n",
        "            multiple_images: gr.update(visible=upload_type == \"Multiple Images\")\n",
        "        }\n",
        "\n",
        "    upload_type.change(\n",
        "        fn=update_visibility,\n",
        "        inputs=upload_type,\n",
        "        outputs=[single_image, multiple_images]\n",
        "    )\n",
        "\n",
        "    # Submit Button Action\n",
        "    submit_btn.click(\n",
        "        fn=gradio_fn,\n",
        "        inputs=[upload_type, single_image, multiple_images, task],\n",
        "        outputs=[doctags_output, markdown_output, proc_time_output, df_output]\n",
        "    )\n",
        "\n",
        "# Launch the demo\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "WeKErZ25xFpt",
        "outputId": "2c2dcacc-1d7f-4a56-e719-141d9f14ad3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8d5ee4883e58f1affa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8d5ee4883e58f1affa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfXHAm0OUfHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}